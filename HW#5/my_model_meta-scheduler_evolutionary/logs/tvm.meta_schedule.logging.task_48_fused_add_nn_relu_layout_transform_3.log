2023-02-16 14:18:38 [INFO] [task_scheduler.cc:158] Initializing Task #48: "fused_add_nn_relu_layout_transform_3"
2023-02-16 14:18:38 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 64, 7, 7, 32), "float32"], p1: T.Buffer[(1, 64, 1, 1, 32), "float32"], T_layout_trans: T.Buffer[(1, 512, 7, 7, 4), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_add = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
        T_relu = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[ax0, ax1, ax2, ax3, ax4], p1[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = p0[ax0, ax1, ax2, ax3, ax4] + p1[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
        for i0, i1, i2, i3, i4 in T.grid(1, 512, 7, 7, 4):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_relu[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 * 4 + ax4 < 2048 and ax2 < 7 and ax3 < 7, T_relu[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32], T.float32(0), dtype="float32")
    

2023-02-16 14:18:38 [INFO] [task_scheduler.cc:162] Total 1 design space(s) generated
2023-02-16 14:18:38 [INFO] [task_scheduler.cc:168] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 64, 7, 7, 32), "float32"], p1: T.Buffer[(1, 64, 1, 1, 32), "float32"], T_layout_trans: T.Buffer[(1, 512, 7, 7, 4), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 512, 7, 7, 4):
                with T.block("T_layout_trans"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32], p1[ax0, (ax1 * 4 + ax4) // 32, 0, 0, (ax1 * 4 + ax4) % 32])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 * 4 + ax4 < 2048 and ax2 < 7 and ax3 < 7, T.max(p0[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32] + p1[ax0, (ax1 * 4 + ax4) // 32, 0, 0, (ax1 * 4 + ax4) % 32], T.float32(0)), T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="T_add", func_name="main")
b1 = sch.get_block(name="T_relu", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:158] Initializing Task #48: "fused_add_nn_relu_layout_transform_3"
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 64, 7, 7, 32), "float32"], p1: T.Buffer[(1, 64, 1, 1, 32), "float32"], T_layout_trans: T.Buffer[(1, 512, 7, 7, 4), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_add = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
        T_relu = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[ax0, ax1, ax2, ax3, ax4], p1[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = p0[ax0, ax1, ax2, ax3, ax4] + p1[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
        for i0, i1, i2, i3, i4 in T.grid(1, 512, 7, 7, 4):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_relu[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 * 4 + ax4 < 2048 and ax2 < 7 and ax3 < 7, T_relu[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32], T.float32(0), dtype="float32")
    

2023-02-16 14:20:38 [INFO] [task_scheduler.cc:162] Total 1 design space(s) generated
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:168] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 64, 7, 7, 32), "float32"], p1: T.Buffer[(1, 64, 1, 1, 32), "float32"], T_layout_trans: T.Buffer[(1, 512, 7, 7, 4), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 512, 7, 7, 4):
                with T.block("T_layout_trans"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32], p1[ax0, (ax1 * 4 + ax4) // 32, 0, 0, (ax1 * 4 + ax4) % 32])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 * 4 + ax4 < 2048 and ax2 < 7 and ax3 < 7, T.max(p0[ax0, (ax1 * 4 + ax4) // 32, ax2, ax3, (ax1 * 4 + ax4) % 32] + p1[ax0, (ax1 * 4 + ax4) // 32, 0, 0, (ax1 * 4 + ax4) % 32], T.float32(0)), T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="T_add", func_name="main")
b1 = sch.get_block(name="T_relu", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
2023-02-16 15:24:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-02-16 15:24:37 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-02-16 15:24:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x212c0cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x2fbc1478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1f67a638)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x2b494148)]: 0 failure(s)
2023-02-16 15:24:38 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-02-16 15:24:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x212c0cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x2fbc1478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1f67a638)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x2b494148)]: 0 failure(s)
2023-02-16 15:24:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x212c0cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x2fbc1478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1f67a638)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x2b494148)]: 0 failure(s)
2023-02-16 15:24:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x212c0cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x2fbc1478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1f67a638)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x2b494148)]: 0 failure(s)
2023-02-16 15:24:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x212c0cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x2fbc1478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1f67a638)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x2b494148)]: 0 failure(s)
2023-02-16 15:24:40 [INFO] [evolutionary_search.cc:649] Scores of the best 1 candidates:
[1 : 1]:	0.4800
2023-02-16 15:24:40 [INFO] [evolutionary_search.cc:727] Got 1 candidate(s) with evolutionary search
2023-02-16 15:24:40 [INFO] [evolutionary_search.cc:730] Sending 1 candidates(s) for measurement
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #48: fused_add_nn_relu_layout_transform_3] Trial #1: GFLOPs: 20.5414. Time: 9.7707 us. Best GFLOPs: 20.5414
