2023-02-16 14:18:38 [INFO] [task_scheduler.cc:158] Initializing Task #47: "fused_nn_contrib_conv2d_NCHWc_add_3"
2023-02-16 14:18:38 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 64, 7, 7, 32, 512, 1, 1):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], p2[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + p2[ax0, ax1, ax2, ax3, ax4]
    

2023-02-16 14:18:38 [INFO] [task_scheduler.cc:162] Total 3 design space(s) generated
2023-02-16 14:18:38 [INFO] [task_scheduler.cc:168] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 2, 1, 1, 4, 1, 1, 7, 1, 8, 256, 1, 1, 1, 16, 1, 7, 1, 2, 1, 1, 1, 2, 1, 1, 1):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, i0_0 + i0_1 + i0_2 + i0_3)
                    oc_chunk = T.axis.spatial(64, i1_0 * 32 + i1_1 * 32 + i1_2 * 2 + i1_3)
                    oh = T.axis.spatial(7, i2_0 * 7 + i2_1 + i2_2 + i2_3)
                    ow = T.axis.spatial(7, i3_3 + i3_0 * 7 + i3_1 * 7 + i3_2)
                    oc_block = T.axis.spatial(32, i4_2 + i4_3 + i4_0 * 8 + i4_1)
                    ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                    kh = T.axis.reduce(1, i6_0 + i6_1)
                    kw = T.axis.reduce(1, i7_1 + i7_0)
                    T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
                with T.block("T_add"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], p2[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                    T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + p2[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 1, 16, 2])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 8, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[256, 2])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
2023-02-16 14:18:38 [INFO] [task_scheduler.cc:168] Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 1, 1, 4, 1, 1, 7, 1, 8):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(256, 1, 1, 1, 16, 1, 7, 1, 2, 1, 1, 1, 2, 1, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, i0_0 + i0_1 + i0_2 + i0_3)
                        oc_chunk = T.axis.spatial(64, i1_0 * 32 + i1_1 * 32 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(7, i2_0 * 7 + i2_1 + i2_2 + i2_3)
                        ow = T.axis.spatial(7, i3_3 + i3_0 * 7 + i3_1 * 7 + i3_2)
                        oc_block = T.axis.spatial(32, i4_2 + i4_3 + i4_0 * 8 + i4_1)
                        ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                        kh = T.axis.reduce(1, i6_0 + i6_1)
                        kw = T.axis.reduce(1, i7_1 + i7_0)
                        T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 32, 1, 7, 1):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(64, i1_0 * 32 + ax1)
                        ax2_1 = T.axis.spatial(7, i2_1 + ax2)
                        ax3_1 = T.axis.spatial(7, ax3)
                        ax4_1 = T.axis.spatial(32, i4_0 * 8 + i4_1 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 1, 16, 2])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 8, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[256, 2])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-02-16 14:18:38 [INFO] [task_scheduler.cc:168] Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 2, 1, 1, 4):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 1, 7, 1, 8, 256, 1, 1, 1, 16, 1, 7, 1, 2, 1, 1, 1, 2, 1, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, i0_0 + i0_1 + i0_2 + i0_3)
                        oc_chunk = T.axis.spatial(64, i1_0 * 32 + i1_1 * 32 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(7, i2_0 * 7 + i2_1 + i2_2 + i2_3)
                        ow = T.axis.spatial(7, i3_3 + i3_0 * 7 + i3_1 * 7 + i3_2)
                        oc_block = T.axis.spatial(32, i4_2 + i4_3 + i4_0 * 8 + i4_1)
                        ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                        kh = T.axis.reduce(1, i6_0 + i6_1)
                        kw = T.axis.reduce(1, i7_1 + i7_0)
                        T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 32, 7, 7, 8):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(64, i1_0 * 32 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4_1 = T.axis.spatial(32, i4_0 * 8 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 1, 16, 2])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 8, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[256, 2])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:158] Initializing Task #47: "fused_nn_contrib_conv2d_NCHWc_add_3"
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 64, 7, 7, 32, 512, 1, 1):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], p2[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + p2[ax0, ax1, ax2, ax3, ax4]
    

2023-02-16 14:20:38 [INFO] [task_scheduler.cc:162] Total 3 design space(s) generated
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:168] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 4, 1, 1, 4, 1, 8, 1, 1, 2, 8, 1, 1, 1, 2, 7, 7, 1, 64, 1, 1, 1, 1, 1, 1, 4):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, i0_0 + i0_1 + i0_2 + i0_3)
                    oc_chunk = T.axis.spatial(64, i1_3 + i1_0 * 16 + i1_1 * 2 + i1_2)
                    oh = T.axis.spatial(7, i2_0 * 7 + i2_1 * 7 + i2_2 + i2_3)
                    ow = T.axis.spatial(7, i3_3 + i3_0 * 7 + i3_1 * 7 + i3_2)
                    oc_block = T.axis.spatial(32, i4_0 * 8 + i4_1 * 4 + i4_2 * 4 + i4_3)
                    ic = T.axis.reduce(512, i5_0 * 64 + i5_1)
                    kh = T.axis.reduce(1, i6_0 + i6_1)
                    kw = T.axis.reduce(1, i7_1 + i7_0)
                    T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 64, 7, 7, 32):
                with T.block("T_add"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], p2[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                    T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + p2[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[4, 8, 2, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[8, 64])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:168] Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 4, 1, 1, 4, 1, 8, 1, 1, 2):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 1, 1, 1, 2, 7, 7, 1, 64, 1, 1, 1, 1, 1, 1, 4):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, i0_0 + i0_1 + i0_2 + i0_3)
                        oc_chunk = T.axis.spatial(64, i1_3 + i1_0 * 16 + i1_1 * 2 + i1_2)
                        oh = T.axis.spatial(7, i2_0 * 7 + i2_1 * 7 + i2_2 + i2_3)
                        ow = T.axis.spatial(7, i3_3 + i3_0 * 7 + i3_1 * 7 + i3_2)
                        oc_block = T.axis.spatial(32, i4_0 * 8 + i4_1 * 4 + i4_2 * 4 + i4_3)
                        ic = T.axis.reduce(512, i5_0 * 64 + i5_1)
                        kh = T.axis.reduce(1, i6_0 + i6_1)
                        kw = T.axis.reduce(1, i7_1 + i7_0)
                        T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 2, 7, 7, 4):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(64, i1_0 * 16 + i1_1 * 2 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4_1 = T.axis.spatial(32, i4_0 * 8 + i4_1 * 4 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[4, 8, 2, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[8, 64])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-02-16 14:20:38 [INFO] [task_scheduler.cc:168] Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(1, 128, 7, 7, 4), "float32"], p1: T.Buffer[(64, 128, 1, 1, 4, 32), "float32"], p2: T.Buffer[(1, 64, 7, 7, 32), "float32"], T_add: T.Buffer[(1, 64, 7, 7, 32), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":96, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 7, 7, 32], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 4, 1, 1, 4):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 8, 1, 1, 2, 8, 1, 1, 1, 2, 7, 7, 1, 64, 1, 1, 1, 1, 1, 1, 4):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, i0_0 + i0_1 + i0_2 + i0_3)
                        oc_chunk = T.axis.spatial(64, i1_3 + i1_0 * 16 + i1_1 * 2 + i1_2)
                        oh = T.axis.spatial(7, i2_0 * 7 + i2_1 * 7 + i2_2 + i2_3)
                        ow = T.axis.spatial(7, i3_3 + i3_0 * 7 + i3_1 * 7 + i3_2)
                        oc_block = T.axis.spatial(32, i4_0 * 8 + i4_1 * 4 + i4_2 * 4 + i4_3)
                        ic = T.axis.reduce(512, i5_0 * 64 + i5_1)
                        kh = T.axis.reduce(1, i6_0 + i6_1)
                        kw = T.axis.reduce(1, i7_1 + i7_0)
                        T.reads(p0[n, ic // 4, oh + kh, ow + kw, ic % 4], p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + p0[n, ic // 4, oh + kh, ow + kw, ic % 4] * p1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 16, 7, 7, 8):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(64, i1_0 * 16 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4_1 = T.axis.spatial(32, i4_0 * 8 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + p2[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[4, 8, 2, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 1, 4])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[8, 64])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=96)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-02-16 15:22:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-02-16 15:22:18 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-02-16 15:22:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 15:22:19 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-02-16 15:22:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 15:22:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 15:22:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 15:22:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 15:22:22 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9996  0.9993  0.9991  0.9986  0.9980  0.9977  0.9955  0.9944  0.9944  0.9928  0.9923  0.9923  0.9923  0.9923  0.9921  0.9919
[17 : 32]:	0.9918  0.9913  0.9892  0.9887  0.9882  0.9879  0.9876  0.9875  0.9866  0.9861  0.9855  0.9855  0.9855  0.9850  0.9836  0.9830
[33 : 48]:	0.9827  0.9824  0.9814  0.9812  0.9806  0.9804  0.9802  0.9789  0.9779  0.9769  0.9768  0.9767  0.9753  0.9753  0.9753  0.9749
[49 : 64]:	0.9748  0.9746  0.9739  0.9739  0.9737  0.9733  0.9733  0.9724  0.9713  0.9710  0.9710  0.9705  0.9699  0.9698  0.9693  0.9690
2023-02-16 15:22:22 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-02-16 15:22:22 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #1: GFLOPs: 3.0712. Time: 33491.8333 us. Best GFLOPs: 3.0712
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #2: GFLOPs: 24.2770. Time: 4236.9708 us. Best GFLOPs: 24.2770
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #3: GFLOPs: 20.0798. Time: 5122.6092 us. Best GFLOPs: 24.2770
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #4: GFLOPs: 67.0704. Time: 1533.6240 us. Best GFLOPs: 67.0704
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #5: GFLOPs: 29.1542. Time: 3528.1633 us. Best GFLOPs: 67.0704
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #6: GFLOPs: 81.7497. Time: 1258.2410 us. Best GFLOPs: 81.7497
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #7: GFLOPs: 11.3864. Time: 9033.6603 us. Best GFLOPs: 81.7497
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #8: GFLOPs: 13.6446. Time: 7538.5741 us. Best GFLOPs: 81.7497
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #9: GFLOPs: 61.6206. Time: 1669.2612 us. Best GFLOPs: 81.7497
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #10: GFLOPs: 42.0010. Time: 2449.0104 us. Best GFLOPs: 81.7497
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #11: GFLOPs: 16.8810. Time: 6093.2879 us. Best GFLOPs: 81.7497
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #12: GFLOPs: 129.2102. Time: 796.0735 us. Best GFLOPs: 129.2102
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #13: GFLOPs: 194.5193. Time: 528.7948 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #14: GFLOPs: 63.9652. Time: 1608.0749 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #15: GFLOPs: 40.2184. Time: 2557.5544 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #16: GFLOPs: 34.6004. Time: 2972.8198 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #17: GFLOPs: 27.3443. Time: 3761.6867 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #18: GFLOPs: 14.9610. Time: 6875.2578 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #19: GFLOPs: 29.9102. Time: 3438.9923 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #20: GFLOPs: 10.8340. Time: 9494.2167 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #21: GFLOPs: 41.7111. Time: 2466.0294 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #22: GFLOPs: 32.1991. Time: 3194.5199 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #23: GFLOPs: 25.2689. Time: 4070.6502 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #24: GFLOPs: 22.0068. Time: 4674.0523 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #25: GFLOPs: 29.3563. Time: 3503.8747 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #26: GFLOPs: 26.6918. Time: 3853.6476 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #27: GFLOPs: 82.3868. Time: 1248.5113 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #28: GFLOPs: 21.7341. Time: 4732.6976 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #29: GFLOPs: 59.5772. Time: 1726.5131 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #30: GFLOPs: 2.8354. Time: 36277.4373 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #31: GFLOPs: 2.0558. Time: 50035.5520 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #32: GFLOPs: 8.5289. Time: 12060.2055 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #33: GFLOPs: 9.0746. Time: 11334.9919 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #34: GFLOPs: 37.1637. Time: 2767.7751 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #35: GFLOPs: 146.1096. Time: 703.9974 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #36: GFLOPs: 15.5251. Time: 6625.4428 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #37: GFLOPs: 58.8218. Time: 1748.6849 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #38: GFLOPs: 55.2860. Time: 1860.5216 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #39: GFLOPs: 50.4252. Time: 2039.8684 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #40: GFLOPs: 88.4417. Time: 1163.0348 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #41: GFLOPs: 52.8603. Time: 1945.9006 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #42: GFLOPs: 16.5014. Time: 6233.4472 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #43: GFLOPs: 82.2934. Time: 1249.9272 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #44: GFLOPs: 13.5457. Time: 7593.6244 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #45: GFLOPs: 29.2654. Time: 3514.7592 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #46: GFLOPs: 15.4380. Time: 6662.8319 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #47: GFLOPs: 94.5887. Time: 1087.4534 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #48: GFLOPs: 38.8349. Time: 2648.6717 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #49: GFLOPs: 2.3760. Time: 43291.5015 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #50: GFLOPs: 38.1734. Time: 2694.5639 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #51: GFLOPs: 37.1721. Time: 2767.1530 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #52: GFLOPs: 41.7458. Time: 2463.9815 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #53: GFLOPs: 29.6187. Time: 3472.8385 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #54: GFLOPs: 47.0561. Time: 2185.9202 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #55: GFLOPs: 28.2546. Time: 3640.4962 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #56: GFLOPs: 26.3738. Time: 3900.1090 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #57: GFLOPs: 2.7119. Time: 37929.3025 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #58: GFLOPs: 95.8748. Time: 1072.8661 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #59: GFLOPs: 59.2467. Time: 1736.1438 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #60: GFLOPs: 46.5273. Time: 2210.7606 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #61: GFLOPs: 24.2728. Time: 4237.7036 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #62: GFLOPs: 79.0551. Time: 1301.1278 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #63: GFLOPs: 109.5822. Time: 938.6630 us. Best GFLOPs: 194.5193
2023-02-16 15:36:41 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #64: GFLOPs: 13.0012. Time: 7911.6165 us. Best GFLOPs: 194.5193
2023-02-16 16:38:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-02-16 16:38:52 [INFO] [evolutionary_search.cc:715] Picked top 64 candidate(s) from database
2023-02-16 16:38:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 16:38:53 [INFO] [evolutionary_search.cc:723] Sampled 448 candidate(s)
2023-02-16 16:38:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 16:38:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 16:38:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 16:39:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x210ff478)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3242d838)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x30b0a358)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x1f94b9a8)]: 0 failure(s)
2023-02-16 16:39:02 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9250  0.9023  0.9023  0.8750  0.8609  0.8526  0.8461  0.8383  0.8379  0.8332  0.8232  0.8043  0.7970  0.7967  0.7707  0.7649
[17 : 32]:	0.7649  0.7636  0.7583  0.7304  0.7256  0.7239  0.7213  0.7210  0.7210  0.7185  0.7170  0.7165  0.7137  0.7104  0.7102  0.7102
[33 : 48]:	0.7068  0.7068  0.7046  0.7019  0.6973  0.6970  0.6965  0.6948  0.6943  0.6934  0.6934  0.6920  0.6920  0.6889  0.6860  0.6853
[49 : 64]:	0.6853  0.6821  0.6821  0.6809  0.6761  0.6761  0.6755  0.6744  0.6714  0.6708  0.6704  0.6687  0.6685  0.6680  0.6667  0.6654
2023-02-16 16:39:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-02-16 16:39:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #65: GFLOPs: 120.5948. Time: 852.9456 us. Best GFLOPs: 194.5193
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #66: GFLOPs: 194.6491. Time: 528.4423 us. Best GFLOPs: 194.6491
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #67: GFLOPs: 94.6362. Time: 1086.9074 us. Best GFLOPs: 194.6491
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #68: GFLOPs: 133.0281. Time: 773.2259 us. Best GFLOPs: 194.6491
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #69: GFLOPs: 209.0319. Time: 492.0819 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #70: GFLOPs: 159.1708. Time: 646.2289 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #71: GFLOPs: 114.2450. Time: 900.3529 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #72: GFLOPs: 207.8334. Time: 494.9196 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #73: GFLOPs: 91.9520. Time: 1118.6358 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #74: GFLOPs: 163.2288. Time: 630.1632 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #75: GFLOPs: 165.9541. Time: 619.8146 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #76: GFLOPs: 136.0445. Time: 756.0821 us. Best GFLOPs: 209.0319
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #77: GFLOPs: 240.0530. Time: 428.4920 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #78: GFLOPs: 142.1801. Time: 723.4544 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #79: GFLOPs: 138.6776. Time: 741.7260 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #80: GFLOPs: 147.5311. Time: 697.2144 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #81: GFLOPs: 152.0929. Time: 676.3025 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #82: GFLOPs: 134.7006. Time: 763.6252 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #83: GFLOPs: 134.1243. Time: 766.9066 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #84: GFLOPs: 62.8525. Time: 1636.5422 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #85: GFLOPs: 152.5674. Time: 674.1989 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #86: GFLOPs: 155.2859. Time: 662.3964 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #87: GFLOPs: 186.3013. Time: 552.1207 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #88: GFLOPs: 153.7716. Time: 668.9195 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #89: GFLOPs: 113.1180. Time: 909.3231 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #90: GFLOPs: 162.3607. Time: 633.5327 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #91: GFLOPs: 154.8295. Time: 664.3491 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #92: GFLOPs: 113.1180. Time: 909.3230 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #93: GFLOPs: 167.7600. Time: 613.1426 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #94: GFLOPs: 118.4919. Time: 868.0829 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #95: GFLOPs: 148.8720. Time: 690.9345 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #96: GFLOPs: 151.2447. Time: 680.0954 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #97: GFLOPs: 154.5149. Time: 665.7015 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #98: GFLOPs: 160.0873. Time: 642.5294 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #99: GFLOPs: 150.7133. Time: 682.4930 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #100: GFLOPs: 89.3252. Time: 1151.5313 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #101: GFLOPs: 145.8070. Time: 705.4584 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #102: GFLOPs: 155.6180. Time: 660.9825 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #103: GFLOPs: 76.0246. Time: 1352.9944 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #104: GFLOPs: 134.6263. Time: 764.0466 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #105: GFLOPs: 200.2487. Time: 513.6654 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #106: GFLOPs: 169.6419. Time: 606.3407 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #107: GFLOPs: 147.4085. Time: 697.7944 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #108: GFLOPs: 106.4851. Time: 965.9639 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #109: GFLOPs: 202.5295. Time: 507.8805 us. Best GFLOPs: 240.0530
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #110: GFLOPs: 256.4188. Time: 401.1438 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #111: GFLOPs: 196.3269. Time: 523.9262 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #112: GFLOPs: 109.0929. Time: 942.8736 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #113: GFLOPs: 76.3875. Time: 1346.5663 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #114: GFLOPs: 158.1168. Time: 650.5369 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #115: GFLOPs: 128.5027. Time: 800.4561 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #116: GFLOPs: 141.6668. Time: 726.0753 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #117: GFLOPs: 74.7628. Time: 1375.8282 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #118: GFLOPs: 123.2332. Time: 834.6841 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #119: GFLOPs: 147.5045. Time: 697.3399 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #120: GFLOPs: 136.8443. Time: 751.6632 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #121: GFLOPs: 149.3282. Time: 688.8239 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #122: GFLOPs: 9.3182. Time: 11038.7111 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #123: GFLOPs: 98.1519. Time: 1047.9757 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #124: GFLOPs: 139.3647. Time: 738.0690 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #125: GFLOPs: 124.7351. Time: 824.6338 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #126: GFLOPs: 17.6886. Time: 5815.0956 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #127: GFLOPs: 31.9404. Time: 3220.3978 us. Best GFLOPs: 256.4188
2023-02-16 16:41:25 [INFO] [task_scheduler.cc:129] [Task #47: fused_nn_contrib_conv2d_NCHWc_add_3] Trial #128: GFLOPs: 21.9654. Time: 4682.8472 us. Best GFLOPs: 256.4188
